{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 11. Recommender systems\n",
    "\n",
    "## Introduction to recommender systems\n",
    "\n",
    "Recommendation algorithms provide the customers of companies such as Netflix, Amazon and YouTube intelligent suggestions about the items they might be interested in. There are many alternative approaches to constructing such algorithms. One of them is called **content-based filtering**, which uses the items' metadata (or descriptive characteristics) as explanatory variables to *e.g.* create models for identifying similar items than those the customer has previously expressed interest to. However, in this module we shall focus on another very common technique called **collaborative filtering**.\n",
    "\n",
    "Collaborative filtering generates recommendations about what the user might enjoy on the basis of collected reactions from other users. This technique can be approached from two alternative directions: **item-based** (looking for items that elicit similar reactions) or **user-based** (looking for users with similar tastes) collaborative filtering. Below, we shall investigate both of these alternative approaches.  "
   ],
   "id": "4f2da71ec522dd1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Item-based collaborative filtering\n",
    "\n",
    "Collaborative filtering requires a dataset of user responses (purchase history, reviews, ratings etc.) concerning a set of items. As an example, let us consider the following simple table of user ratings given by six users U1, ..., U6 to a set of four different movies M1, ..., M4.\n",
    "\n",
    "\n",
    "|        | U1  | U2  | U3  | U4  | U5  | U6  | \n",
    "|:------:|:---:|:---:|:---:|:---:|:---:|:---:|\n",
    "| **M1** |  1  |  5  |  5  |     |  2  |  1  |\n",
    "| **M2** |  1  |  5  |     |  1  |     |  1  |\n",
    "| **M3** |  5  |  2  |     |  5  |     |  5  |\n",
    "| **M4** |  5  |  2  |     |     |  4  |     |\n",
    "\n",
    "For example, user U5 has given movie M1 a rating of 2 stars. Empty slots in the table indicate that the user has not yet seen the movie, or has not submitted a rating. Let us also store the same information as a pandas DataFrame: "
   ],
   "id": "afa86070019af56"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:05:19.605993Z",
     "start_time": "2024-09-22T17:05:19.283439Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = {'item': ['M1', 'M2', 'M3', 'M4', 'M1', 'M2', 'M3', 'M4', 'M1', 'M3', 'M2', 'M1', 'M4','M1','M2','M3'],\n",
    "           'user': ['U1', 'U1', 'U1', 'U1', 'U2', 'U2', 'U2', 'U2', 'U3','U4', 'U4', 'U5', 'U5', 'U6', 'U6', 'U6'],\n",
    "           'rating': [1,1,5,5,5,5,2,2,5,5,1,2,4,1,1,5]}\n",
    "\n",
    "df = pd.DataFrame(ratings)\n",
    "df"
   ],
   "id": "6be92fcc6504b5ac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   item user  rating\n",
       "0    M1   U1       1\n",
       "1    M2   U1       1\n",
       "2    M3   U1       5\n",
       "3    M4   U1       5\n",
       "4    M1   U2       5\n",
       "5    M2   U2       5\n",
       "6    M3   U2       2\n",
       "7    M4   U2       2\n",
       "8    M1   U3       5\n",
       "9    M3   U4       5\n",
       "10   M2   U4       1\n",
       "11   M1   U5       2\n",
       "12   M4   U5       4\n",
       "13   M1   U6       1\n",
       "14   M2   U6       1\n",
       "15   M3   U6       5"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>user</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M1</td>\n",
       "      <td>U1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M2</td>\n",
       "      <td>U1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M3</td>\n",
       "      <td>U1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M4</td>\n",
       "      <td>U1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M1</td>\n",
       "      <td>U2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>M2</td>\n",
       "      <td>U2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>M3</td>\n",
       "      <td>U2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>M4</td>\n",
       "      <td>U2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>M1</td>\n",
       "      <td>U3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>M3</td>\n",
       "      <td>U4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>M2</td>\n",
       "      <td>U4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>M1</td>\n",
       "      <td>U5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>M4</td>\n",
       "      <td>U5</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>M1</td>\n",
       "      <td>U6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>M2</td>\n",
       "      <td>U6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>M3</td>\n",
       "      <td>U6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Suppose now that we would like to recommend a movie to user four, U4. There are two alternatives that this user has not yet seen: M1 and M4. Looking at the table, which would you think U4 would prefer? \n",
    "\n",
    "First, note that U4 has given good ratings to M3. It would then be reasonable to expect that U4 might enjoy another movie with similar rating characteristics than M3. Next, comparing the last two rows of numbers in the above table, we find that M4 has a rating history that has some similarities with that of M3 (for example, both U1 and U2 have given these two movies the same ratings). In contrast, the ratings received by M1 (the first row) are clearly different from those received by M3 (and fairly similar to those of M2, which U4 did not like). Therefore, we conclude that U4 would probably prefer M4 to M1. This is the essential logic behind item-based collaborative filtering.\n",
    "\n",
    "More precisely, we wish to predict some unknown rating in the table (to fill in the blanks), say that for M4 as given by U4. Item-based collaborative filtering can be used for that purpose as follows:\n",
    "\n",
    "-  Look for items with user responses that are nearest to those of the item under consideration, and have been rated by the user in question.\n",
    "- Estimate the unknown rating by calculating the weighted average of the known ratings with these nearest neighbor items.\n",
    "\n",
    "For finding the nearest neighbor items, we need a measure of similarity. Each item (or row in the data) can be viewed as a vector with numerical values; the number of these vector components is equal to the number of users. One possible way of obtaining a similarity measure between two such vectors is the familiar Euclidian distance. However, another very often used similarity measure in the context of recommender systems is the **cosine similarity**."
   ],
   "id": "f999358e157ce6eb"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Cosine similarity: a new measure of distance\n",
    "\n",
    "Consider two $N$-dimensional vectors $a = (a_{1}, a_{2}, ..., a_{N})$ and $b = (b_{1}, b_{2}, ..., b_{N})$. The **dot product** $a \\cdot b$ of these vectors is defined as\n",
    "\n",
    "$$\n",
    "a \\cdot b = a_{1}b_{1} + a_{2}b_{2} + ... + a_{N}b_{N},\n",
    "$$\n",
    "and is related to the absolute value (length) of the vectors and the angle $\\theta$ between them as\n",
    "\n",
    "$$\n",
    "a \\cdot b = \\vert a \\vert \\vert b \\vert \\cos\\theta,\n",
    "$$\n",
    "where $\\vert a \\vert = \\sqrt{a_{1}^2 + ... + a_{N}^2}$, and similarly for $\\vert b \\vert$. Accordingly, the cosine similarity $sim(a,b)$ between two item vectors $a$ and $b$ is\n",
    "\n",
    "$$\n",
    "sim(a,b) = \\frac{a \\cdot b}{\\vert a \\vert \\vert b \\vert}.\n",
    "$$ \n",
    "The cosine similarity ranges between 1 (parallel vectors pointing in the same direction) and -1 (antiparallel vectors pointing in opposite directions); larger values indicate more similarity between the vector directions. \n",
    "\n",
    "Using the example data above, let us calculate the cosine similarities between items M3 and M4, substituting zeroes for unknown component values in the row vectors. Since M3 = (5, 2, 0, 5, 0, 5), and M4 = (5, 2, 0, 0, 4, 0), we obtain\n",
    "\n",
    "$$\n",
    "sim(M3, M4) = \\frac{25 + 4 + 0 + 0 + 0 + 0}{\\sqrt{79} \\cdot \\sqrt{45}} \\approx 0,49.\n",
    "$$ \n",
    "A similar analysis between M2 = (1, 5, 0, 1, 0, 1) and M4 gives $sim(M2, M4) \\approx 0,42$, which is a little bit lower, but not by very much. Since we know that U4 has given a rating of 1 to M2, and a rating of 5 to M3, we could estimate the unknown rating U4 would give M4 as a weighted average\n",
    "\n",
    "$$\n",
    "r(U4, M4) = \\frac{sim(M2, M4)r(U4, M2) + sim(M3, M4)r(U4, M3)}{sim(M2, M4)+sim(M3, M4)}\n",
    "\\approx \\frac{0,42 \\cdot 1 + 0,49 \\cdot 5}{0,42 + 0,49} \\approx 3,1.\n",
    "$$\n",
    "Usually, the weighted average is taken with $k$ nearest-neighbor items rated by the user. For the movie M1, an identical analysis would give the estimated rating of $r(U4, M1) \\approx 2,2$ stars, so from these two alternatives, a better recommendation for U4 would seem to be movie M4.\n",
    "\n",
    "Item-based collaborative filtering often produces good results, but in some cases the recommendations might turn out to be somewhat too obvious. Two Harry Potter movies are likely to end up with similar user reactions, but recommending another film in the same series is not terribly useful for the customer, who probably can think of this without an algorithm's help. Our next topic, **user-based collaborative filtering**, can sometimes produce more interesting results  "
   ],
   "id": "33299c3a21d28c1f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## User-based collaborative filtering\n",
    "\n",
    "In user-based collaborative filtering, the aim is to find similar users instead of similar items: if other users' tastes are similar to yours, and they like a certain item, you might also turn out to like it. \n",
    "\n",
    "While in item-based collaborative filtering we compared row vectors for different items, in user-based collaborative filtering we compare *column vectors* indicating the ratings given by individual users. Otherwise, the procedure is entirely similar: the similarity between users U1 and U2, for example can be quantified by calculating the cosine similarity of U1 = (1, 1, 5, 5) and U2 = (5, 5, 2, 2). The result is\n",
    "\n",
    "$$\n",
    "r(U1, U2) = \\frac{30}{\\sqrt{52}\\cdot\\sqrt{58}} \\approx 0,55\n",
    "$$ \n",
    "while that between U1 and U6 is larger: $r(U1, U6) \\approx 0,72$. User-based collaborative filtering for predicting an unknown rating in the ratings table can then be implemented as follows:\n",
    "\n",
    "-  Look for users whose ratings are nearest to those of the user under consideration, and who have rated the item in question.\n",
    "- Estimate the unknown rating by calculating the weighted average of the known ratings given by these nearest-neighbor users.\n",
    "\n",
    "When the predicted ratings for the user have been calculated for the items with missing values, the highest ratings among them can be presented as recommendations.\n",
    "\n",
    "Because the mathematical principles behind collaborative filtering are quite simple, the necessary Python code could be programmed from scratch relatively easily. However, recommender system algorithms are also available through the add-on SciKit package **Surprise**. In the following, we look at how to implement user-based collaborative filtering with Surprise.   "
   ],
   "id": "37037b80249928a3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Python implementation of user-based collaborative filtering\n",
    "\n",
    "To install Surprise, follow the instructions in [https://pypi.org/project/scikit-surprise/](https://pypi.org/project/scikit-surprise/). After the installation, the pandas DataFrame can be read and converted into a Surprise Dataset object as follows (note that the scale of the rating values needs to be given as parameter to the Reader object): "
   ],
   "id": "8020c58ae81deedb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:05:28.132759Z",
     "start_time": "2024-09-22T17:05:27.967211Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from surprise import Reader, Dataset\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5)) \n",
    "data = Dataset.load_from_df(df[['user', 'item', 'rating']], reader)"
   ],
   "id": "fba36ce17592183d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Next, the full dataset is declared to be used for training, after which the training options are determined in a dictionary. Note that to execute item-based collaborative filtering, the option 'user_based' should be set to `False`. After this, the model is trained, during which the similarity values for the dataset are computed.",
   "id": "f166b709544f65a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:05:32.956589Z",
     "start_time": "2024-09-22T17:05:32.946795Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from surprise import KNNBasic\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "sim_options = {\n",
    "    'name': 'cosine', # similarity measure\n",
    "    'user_based': True,  # this setting is for user-based CF\n",
    "}\n",
    "\n",
    "algo = KNNBasic(sim_options=sim_options)\n",
    "algo.fit(trainset)"
   ],
   "id": "912c08b0f7df13b1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNBasic at 0x24d7cbc2450>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The model can now be used to output predictions for individual user ratings:",
   "id": "aba7684644cf4e5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:05:38.444745Z",
     "start_time": "2024-09-22T17:05:38.435610Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_id = 'U4'\n",
    "item_id = 'M4'\n",
    "\n",
    "pred = algo.predict(user_id, item_id, verbose=True)"
   ],
   "id": "fe468712f16dd3bc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: U4         item: M4         r_ui = None   est = 3.94   {'actual_k': 2, 'was_impossible': False}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The following code can be used to predict ratings for all user-item pairs that are missing in the training set.",
   "id": "8a8509e9d9b2458c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:05:43.529067Z",
     "start_time": "2024-09-22T17:05:43.520487Z"
    }
   },
   "cell_type": "code",
   "source": [
    "testset = trainset.build_anti_testset()\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "print(predictions)"
   ],
   "id": "f36f3d29c994d23f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prediction(uid='U3', iid='M2', r_ui=3.125, est=2.3333333333333335, details={'actual_k': 3, 'was_impossible': False}), Prediction(uid='U3', iid='M3', r_ui=3.125, est=4.0, details={'actual_k': 3, 'was_impossible': False}), Prediction(uid='U3', iid='M4', r_ui=3.125, est=3.6666666666666665, details={'actual_k': 3, 'was_impossible': False}), Prediction(uid='U4', iid='M1', r_ui=3.125, est=1.8581466328409297, details={'actual_k': 3, 'was_impossible': False}), Prediction(uid='U4', iid='M4', r_ui=3.125, est=3.9401555395139165, details={'actual_k': 2, 'was_impossible': False}), Prediction(uid='U5', iid='M2', r_ui=3.125, est=2.102303252963153, details={'actual_k': 3, 'was_impossible': False}), Prediction(uid='U5', iid='M3', r_ui=3.125, est=4.173272560277636, details={'actual_k': 3, 'was_impossible': False}), Prediction(uid='U6', iid='M4', r_ui=3.125, est=3.9811530525759653, details={'actual_k': 3, 'was_impossible': False})]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The code in the following cell has been copied from [https://surprise.readthedocs.io/en/stable/FAQ.html](https://surprise.readthedocs.io/en/stable/FAQ.html), and can be used to output top-N recommendations for each of the users:",
   "id": "eda089de1d83112a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-22T17:05:48.130836Z",
     "start_time": "2024-09-22T17:05:48.124570Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def get_top_n(predictions, n=10):\n",
    "    \"\"\"Return the top-N recommendation for each user from a set of predictions.\n",
    "\n",
    "    Args:\n",
    "        predictions(list of Prediction objects): The list of predictions, as\n",
    "            returned by the test method of an algorithm.\n",
    "        n(int): The number of recommendation to output for each user. Default\n",
    "            is 10.\n",
    "\n",
    "    Returns:\n",
    "    A dict where keys are user (raw) ids and values are lists of tuples:\n",
    "        [(raw item id, rating estimation), ...] of size n.\n",
    "    \"\"\"\n",
    "\n",
    "    # First map the predictions to each user.\n",
    "    top_n = defaultdict(list)\n",
    "    for uid, iid, true_r, est, _ in predictions:\n",
    "        top_n[uid].append((iid, est))\n",
    "\n",
    "    # Then sort the predictions for each user and retrieve the k highest ones.\n",
    "    for uid, user_ratings in top_n.items():\n",
    "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        top_n[uid] = user_ratings[:n]\n",
    "\n",
    "    return top_n\n",
    "\n",
    "\n",
    "top_n = get_top_n(predictions, n=2)\n",
    "\n",
    "# Print the recommended items for each user\n",
    "for uid, user_ratings in top_n.items():\n",
    "    print(uid, [iid for (iid, _) in user_ratings])"
   ],
   "id": "876c97aa62af33f0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U3 ['M3', 'M4']\n",
      "U4 ['M4', 'M1']\n",
      "U5 ['M3', 'M2']\n",
      "U6 ['M4']\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8632fd58f34290b4"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
